{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory):\n",
    "    \"\"\"\n",
    "    List all files in a directory and its subdirectories.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory to search for files.\n",
    "\n",
    "    Returns:\n",
    "        list: List of file paths.\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            paths.append(os.path.join(root, file))\n",
    "    return paths\n",
    "\n",
    "def get_leaf_directory(path):\n",
    "    \"\"\"\n",
    "    Get the leaf directory name from a given path.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path.\n",
    "\n",
    "    Returns:\n",
    "        str: The leaf directory name.\n",
    "    \"\"\"\n",
    "    return os.path.basename(os.path.dirname(path))\n",
    "\n",
    "def oldest_date_value(group):\n",
    "    \"\"\"\n",
    "    Get the file path corresponding to the oldest date in the group.\n",
    "\n",
    "    Args:\n",
    "        group (pd.Series): The group of file paths.\n",
    "\n",
    "    Returns:\n",
    "        str: The file path with the oldest date.\n",
    "    \"\"\"\n",
    "    if not group.empty:\n",
    "        return group.loc[group['date'].idxmin(), 'input_path']\n",
    "    return None\n",
    "\n",
    "def get_base_directory_and_file(path):\n",
    "    \"\"\"\n",
    "    Get the base directory and file name from a path.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path.\n",
    "\n",
    "    Returns:\n",
    "        str: The combined base directory and file name.\n",
    "    \"\"\"\n",
    "    dir_name = os.path.basename(os.path.dirname(path))\n",
    "    file_name = os.path.basename(path)\n",
    "    return os.path.join(dir_name, file_name)\n",
    "\n",
    "def remove_extension(filename):\n",
    "        return re.sub(r'(\\.\\w+)+$', '', filename)\n",
    "\n",
    "def generate_sample_sheet(input_dir, output_dir, input_ext='.nd2', output_ext='.nd2'):\n",
    "    \"\"\"\n",
    "    Generate a sample sheet with input and output paths.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): The directory containing input files.\n",
    "        output_dir (str): The directory to store output files.\n",
    "        file_extension (str): The file extension to filter by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The generated sample sheet.\n",
    "    \"\"\"\n",
    "    input_paths = [path for path in list_files(input_dir) if path.endswith(input_ext)]\n",
    "    patient_ids = [os.path.basename(path).split('_', 1)[0] for path in input_paths]\n",
    "    sample_sheet = pd.DataFrame({'patient_id': patient_ids, 'input_path': input_paths})\n",
    "\n",
    "    # Function to join dir_path with the filename\n",
    "    def join_path(file_path):\n",
    "        return os.path.join(output_dir, file_path)\n",
    "\n",
    "    sample_sheet['base_dir'] = sample_sheet['input_path'].apply(get_base_directory_and_file)\n",
    "    sample_sheet['output_path'] = sample_sheet['base_dir'].apply(join_path)\n",
    "    sample_sheet.drop(columns=['base_dir'], inplace=True)\n",
    "    sample_sheet['output_path'] = sample_sheet['output_path'].apply(remove_extension) + output_ext\n",
    "    return sample_sheet\n",
    "\n",
    "def get_fixed_image(sample_sheet):\n",
    "    sample_sheet['date'] = pd.to_datetime(sample_sheet['input_path'].str.extract(r'(\\d{4}\\.\\d{2}\\.\\d{2})')[0], format='%Y.%m.%d')\n",
    "    sample_sheet.dropna(subset=['date'], inplace=True)\n",
    "    sample_sheet.sort_values(by=['patient_id', 'date'], inplace=True)\n",
    "    sample_sheet['fixed_image_path'] = sample_sheet.groupby('patient_id')['input_path'].transform(lambda x: oldest_date_value(sample_sheet.loc[x.index]))\n",
    "    sample_sheet.drop(columns=['date'], inplace=True)\n",
    "    sample_sheet.sort_values(by=['patient_id'], inplace=True)\n",
    "    return sample_sheet\n",
    "\n",
    "def make_missing_dirs(sample_sheet):\n",
    "    output_subdirs = list(sample_sheet['output_path'].apply(os.path.dirname))\n",
    "    output_subdirs = list(set(output_subdirs))\n",
    "    print(output_subdirs)\n",
    "    for dir in output_subdirs:\n",
    "        if not os.path.exists(dir):\n",
    "            # os.mkdir(dir)\n",
    "            print(f'Created directory: {dir}')\n",
    "        else:\n",
    "            print(f'Directory already exists: {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/Volumes'\n",
    "root_dir = '/hpcnfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = root_dir + '/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input'\n",
    "output_dir = root_dir + '/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output'\n",
    "\n",
    "sample_sheet = generate_sample_sheet(input_dir, output_dir, input_ext='.nd2', output_ext='.nd2')\n",
    "samples_to_process = sample_sheet[~sample_sheet['output_path'].apply(os.path.exists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>input_path</th>\n",
       "      <th>output_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.08.06_DAPI_MLH1/2_DAPI_MLH1.nd2</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.08.06_DAPI_MLH1/2_DAPI_MLH1.nd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.08.06_DAPI_MLH1/1_DAPI_MLH1.nd2</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.08.06_DAPI_MLH1/1_DAPI_MLH1.nd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.07.09_ARP18_COV19/2_ARP18_COV19.nd2</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.07.09_ARP18_COV19/2_ARP18_COV19.nd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.07.09_ARP18_COV19/1_ARP18_COV19.nd2</td>\n",
       "      <td>/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.07.09_ARP18_COV19/1_ARP18_COV19.nd2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  \\\n",
       "0  2           \n",
       "1  1           \n",
       "2  2           \n",
       "3  1           \n",
       "\n",
       "                                                                                                                                           input_path  \\\n",
       "0  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.08.06_DAPI_MLH1/2_DAPI_MLH1.nd2       \n",
       "1  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.08.06_DAPI_MLH1/1_DAPI_MLH1.nd2       \n",
       "2  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.07.09_ARP18_COV19/2_ARP18_COV19.nd2   \n",
       "3  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/input/2024.07.09_ARP18_COV19/1_ARP18_COV19.nd2   \n",
       "\n",
       "                                                                                                                                           output_path  \n",
       "0  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.08.06_DAPI_MLH1/2_DAPI_MLH1.nd2      \n",
       "1  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.08.06_DAPI_MLH1/1_DAPI_MLH1.nd2      \n",
       "2  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.07.09_ARP18_COV19/2_ARP18_COV19.nd2  \n",
       "3  /hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/tests/data/output/2024.07.09_ARP18_COV19/1_ARP18_COV19.nd2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/output/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sheet.to_csv('/hpcnfs/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/output/test_sample_sheet.csv', index=False)\n",
    "# sample_sheet = pd.read_csv(root_dir + '/scratch/DIMA/chiodin/repositories/image_registration_pipeline/image_registration/output/sample_sheet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: output file \"2024/1_DAPI_MLH1\": no correspondence found in input directory.\n"
     ]
    }
   ],
   "source": [
    "# Check that all output files have a correspondence in the input files list\n",
    "input_files_stripped = [re.sub(r'\\.\\w+', '', get_base_directory_and_file(file)) for file in list_files(input_dir)]\n",
    "output_files_stripped = [re.sub(r'\\.\\w+', '', get_base_directory_and_file(file)) for file in list_files(output_dir)]\n",
    "\n",
    "for file in output_files_stripped:\n",
    "    if file not in input_files_stripped:\n",
    "        print(f'Warning: output file \"{file}\": no correspondence found in input directory.')\n",
    "\n",
    "\n",
    "# Check that all output files are in log\n",
    "for element in list_files(output_dir):\n",
    "    if element not in list(sample_sheet['output_path']):\n",
    "        print(f'Warning: output file {element} not found in processed files log.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
